{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WdgFUVoGGcN-"
   },
   "source": [
    "## DATA \n",
    "Getting Data from the keras datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-tf4_y_peWLx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "NUM_WORDS=10000\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=NUM_WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MzRMR6uGstGA"
   },
   "source": [
    "### Data Insights\n",
    "1. \\# of training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "dqEBDVxKGnFF",
    "outputId": "34f4d957-ba37-468a-8120-092f8236daa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Len\n",
      " 8982\n",
      "Test Data Len\n",
      " 2246\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Data Len\\n\",len(train_data))\n",
    "print(\"Test Data Len\\n\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gAxzB1QwIiX6"
   },
   "source": [
    "## Explore train data......"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KCnnJ549KwGQ"
   },
   "source": [
    "#### 1. Sample train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "uwro8LRYHe7y",
    "outputId": "eb36a5c7-e384-435c-c6f5-d28fb54ca8c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 245,\n",
       " 273,\n",
       " 207,\n",
       " 156,\n",
       " 53,\n",
       " 74,\n",
       " 160,\n",
       " 26,\n",
       " 14,\n",
       " 46,\n",
       " 296,\n",
       " 26,\n",
       " 39,\n",
       " 74,\n",
       " 2979,\n",
       " 3554,\n",
       " 14,\n",
       " 46,\n",
       " 4689,\n",
       " 4329,\n",
       " 86,\n",
       " 61,\n",
       " 3499,\n",
       " 4795,\n",
       " 14,\n",
       " 61,\n",
       " 451,\n",
       " 4329,\n",
       " 17,\n",
       " 12]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " train_data[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P13AgOmXs-oh"
   },
   "source": [
    "Thus training data is a set of indices of the words from word dictionary. We need to get actual data of sentences to work with Logistic Regression analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y4ZFisr1K5eT"
   },
   "source": [
    "#### Sample Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "64U6P6SnK9_2",
    "outputId": "20642114-fdea-400d-c80f-ee8675691329"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  4,  3,  4,  4,  4,  4,  3,  3, 16])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " train_labels[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NQlyUclYtVDb"
   },
   "source": [
    "##### Recovering original data by reverse dictionary look up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RiyQs1X1IsqF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/reuters_word_index.json\n",
      "557056/550378 [==============================] - 0s 1us/step\n"
     ]
    }
   ],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "\n",
    "def get_original_data(data):\n",
    "  orig_data = []\n",
    "\n",
    "  for i in range(0, len(data)):\n",
    "    orig_data.append( ' '.join([reverse_word_index.get(i - 3, '?') for i in data[i]]) )\n",
    "  \n",
    "  return orig_data\n",
    "\n",
    "X_train_orig = get_original_data(train_data)\n",
    "X_test_orig = get_original_data(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4_ezKto5Lms_"
   },
   "source": [
    "#### Sample Orignal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "jvOeHVgCLpcm",
    "outputId": "75bd5aad-b71b-4dc1-a8af-3b9a019c7310"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3',\n",
       " '? generale de banque sa lt ? br and lt heller overseas corp of chicago have each taken 50 pct stakes in ? company sa ? factors generale de banque said in a statement it gave no financial details of the transaction sa ? ? turnover in 1986 was 17 5 billion belgian francs reuter 3',\n",
       " '? shr 3 28 dlrs vs 22 cts shr diluted 2 99 dlrs vs 22 cts net 46 0 mln vs 3 328 000 avg shrs 14 0 mln vs 15 2 mln year shr 5 41 dlrs vs 1 56 dlrs shr diluted 4 94 dlrs vs 1 50 dlrs net 78 2 mln vs 25 9 mln avg shrs 14 5 mln vs 15 1 mln note earnings per share reflect the two for one split effective january 6 1987 per share amounts are calculated after preferred stock dividends loss continuing operations for the qtr 1986 includes gains of sale of investments in ? corp of 14 mln dlrs and associated companies of 4 189 000 less writedowns of investments in national ? inc of 11 8 mln and ? corp of 15 6 mln reuter 3',\n",
       " \"? the farmers home administration the u s agriculture department's farm lending arm could lose about seven billion dlrs in outstanding principal on its severely ? borrowers or about one fourth of its farm loan portfolio the general accounting office gao said in remarks prepared for delivery to the senate agriculture committee brian crowley senior associate director of gao also said that a preliminary analysis of proposed changes in ? financial eligibility standards indicated as many as one half of ? borrowers who received new loans from the agency in 1986 would be ? under the proposed system the agency has proposed evaluating ? credit using a variety of financial ratios instead of relying solely on ? ability senate agriculture committee chairman patrick leahy d vt ? the proposed eligibility changes telling ? administrator ? clark at a hearing that they would mark a dramatic shift in the agency's purpose away from being farmers' lender of last resort toward becoming a big city bank but clark defended the new regulations saying the agency had a responsibility to ? its 70 billion dlr loan portfolio in a ? yet ? manner crowley of gao ? ? arm said the proposed credit ? system attempted to ensure that ? would make loans only to borrowers who had a reasonable change of repaying their debt reuter 3\",\n",
       " '? seton co said its board has received a proposal from chairman and chief executive officer philip d ? to acquire seton for 15 75 dlrs per share in cash seton said the acquisition bid is subject to ? arranging the necessary financing it said he intends to ask other members of senior management to participate the company said ? owns 30 pct of seton stock and other management members another 7 5 pct seton said it has formed an independent board committee to consider the offer and has deferred the annual meeting it had scheduled for march 31 reuter 3']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_orig[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yt_IrusxOfFF"
   },
   "source": [
    "Before building the bag of words model, we will examine the distribution of training labales. This will give us insights into \n",
    "\n",
    "How **balanced** the data is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "nD43SInsLtW-",
    "outputId": "d0832670-aecf-4f66-f9a1-cad95b5a6c37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.55019763,  0.45199275,  2.6386604 ,  0.06181097,  0.10018516,\n",
       "       11.4859335 ,  4.06793478, 12.20380435,  1.40475446,  1.93327594,\n",
       "        1.57468443,  0.5006689 ,  3.98491571,  1.13523761,  7.51003344,\n",
       "        9.76304348,  0.43977673,  5.00668896,  2.95849802,  0.35566643,\n",
       "        0.72587684,  1.9526087 , 13.0173913 ,  4.76246023,  3.14936886,\n",
       "        2.12240076,  8.13586957, 13.0173913 ,  4.06793478, 10.27688787,\n",
       "        4.33913043,  5.00668896,  6.10190217, 17.75098814,  3.90521739,\n",
       "       19.52608696,  3.98491571, 10.27688787, 10.27688787,  8.13586957,\n",
       "        5.42391304,  6.50869565, 15.02006689,  9.29813665, 16.27173913,\n",
       "       10.84782609])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import class_weight   # Using class weights function of sklearn to explore data \n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(train_labels), train_labels)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zIugOH-dPQYT"
   },
   "source": [
    "#### Explore class distribution \n",
    "Ploting class distribution as a bar graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "NSX6N1bJO2uN",
    "outputId": "b2b1dc93-c4f3-4fa5-b6ec-e47b2e427e8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 46 artists>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAARgUlEQVR4nO3dfaxlVX3G8e8jYG3VFpArjgPj2JYQqZGR3AwYWosv4DAQsY21EKvT1mbUYIKJpkXbiMU2oWl8ScVIpzABG4rYKkoqvkwQgyaKXnBQcLQgGcs4E2YQBIxGM/rrH3dPPVzOmXvn7HvnZZ3vJzk5e6+99t7rbDLPXayz9zqpKiRJ7XrSgW6AJGlpGfSS1DiDXpIaZ9BLUuMMeklq3OEHugHDHHPMMbVy5coD3QxJOmTcfvvtD1bV1LBtB2XQr1y5kpmZmQPdDEk6ZCT5/qhtDt1IUuPmDfokxye5JcmWJHcnuagrPzrJpiT3dO9Hjdh/XVfnniTrFvsDSJL2biE9+t3A26rqecBpwIVJTgIuBm6uqhOAm7v1x0lyNHAJcCqwGrhk1B8ESdLSmDfoq2pHVd3RLT8GbAGWA+cB13TVrgFeNWT3VwCbquqhqnoY2ASsWYyGS5IWZp/G6JOsBF4I3AYcW1U7YPaPAfDMIbssB+4fWN/WlQ079vokM0lmdu3atS/NkiTtxYKDPsnTgI8Db62qRxe625CyobOoVdWGqpququmpqaF3CEmSxrCgoE9yBLMhf21VfaIrfiDJsm77MmDnkF23AccPrB8HbB+/uZKkfbWQu24CXAVsqar3DWy6EdhzF8064FNDdv8ccFaSo7ovYc/qyiRJ+8lCevSnA68DXppkc/daC1wGnJnkHuDMbp0k00muBKiqh4D3AF/vXpd2ZZKk/SQH4w+PTE9Pl0/GSoeulRd/ep/32XrZOUvQksmR5Paqmh62zSdjJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXGHz1chyUbgXGBnVT2/K7seOLGrciTwo6paNWTfrcBjwC+A3aN+/USStHTmDXrgauBy4CN7CqrqT/csJ3kv8Mhe9n9JVT04bgMlHVjj/CygDi7zBn1V3Zpk5bBtSQK8Bnjp4jZLkrRY+o7R/wHwQFXdM2J7AZ9PcnuS9Xs7UJL1SWaSzOzatatnsyRJe/QN+guA6/ay/fSqOgU4G7gwyYtHVayqDVU1XVXTU1NTPZslSdpj7KBPcjjwx8D1o+pU1fbufSdwA7B63PNJksbTp0f/cuA7VbVt2MYkT03y9D3LwFnAXT3OJ0kaw7xBn+Q64CvAiUm2JXlDt+l85gzbJHl2kpu61WOBLye5E/ga8Omq+uziNV2StBALuevmghHlfz6kbDuwtlu+Dzi5Z/skST35ZKwkNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY1byDTFkqQRxpnGeetl5yxBS0azRy9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQv5zdiNSXYmuWug7N1JfpBkc/daO2LfNUm+m+TeJBcvZsMlSQuzkB791cCaIeXvr6pV3eumuRuTHAZ8CDgbOAm4IMlJfRorSdp38wZ9Vd0KPDTGsVcD91bVfVX1c+CjwHljHEeS1EOf2SvfkuT1wAzwtqp6eM725cD9A+vbgFNHHSzJemA9wIoVK3o0S5LGM85MlIeCcb+M/TDwO8AqYAfw3iF1MqSsRh2wqjZU1XRVTU9NTY3ZLEnSXGMFfVU9UFW/qKpfAv/G7DDNXNuA4wfWjwO2j3M+SdL4xgr6JMsGVv8IuGtIta8DJyR5bpInA+cDN45zPknS+OYdo09yHXAGcEySbcAlwBlJVjE7FLMVeGNX99nAlVW1tqp2J3kL8DngMGBjVd29JJ9CkjTSvEFfVRcMKb5qRN3twNqB9ZuAJ9x6KUnaf3wyVpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMb1+XFwqRnj/Cj01svOaa4NapM9eklq3LxBn2Rjkp1J7hoo++ck30nyzSQ3JDlyxL5bk3wryeYkM4vZcEnSwiykR381sGZO2Sbg+VX1AuB/gHfsZf+XVNWqqpoer4mSpD7mDfqquhV4aE7Z56tqd7f6VeC4JWibJGkRLMYY/V8CnxmxrYDPJ7k9yfq9HSTJ+iQzSWZ27dq1CM2SJEHPoE/yt8Bu4NoRVU6vqlOAs4ELk7x41LGqakNVTVfV9NTUVJ9mSZIGjB30SdYB5wKvraoaVqeqtnfvO4EbgNXjnk+SNJ6x7qNPsgb4G+APq+onI+o8FXhSVT3WLZ8FXDp2Sxvm/dOSltJCbq+8DvgKcGKSbUneAFwOPB3Y1N06eUVX99lJbup2PRb4cpI7ga8Bn66qzy7Jp5AkjTRvj76qLhhSfNWIutuBtd3yfcDJvVonSerNJ2MlqXEGvSQ1zqCXpMYZ9JLUOINekhrnfPSLbJx74iVpKdmjl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY3z9kpJ2s9G3Ya9VNOP26OXpMYZ9JLUOINekhpn0EtS4wx6SWrcgu66SbIROBfYWVXP78qOBq4HVgJbgddU1cND9l0H/F23+g9VdU3/ZkuCtn5YfrEnBDxYP+eBsNAe/dXAmjllFwM3V9UJwM3d+uN0fwwuAU4FVgOXJDlq7NZKkvbZgoK+qm4FHppTfB6wp3d+DfCqIbu+AthUVQ91vf1NPPEPhiRpCfUZoz+2qnYAdO/PHFJnOXD/wPq2ruwJkqxPMpNkZteuXT2aJUkatNRfxmZIWQ2rWFUbqmq6qqanpqaWuFmSNDn6TIHwQJJlVbUjyTJg55A624AzBtaPA77Y45w6BLT0BaHUgj49+huBdd3yOuBTQ+p8DjgryVHdl7BndWWSpP1kQUGf5DrgK8CJSbYleQNwGXBmknuAM7t1kkwnuRKgqh4C3gN8vXtd2pVJkvaTBQ3dVNUFIza9bEjdGeCvBtY3AhvHap0kqTefjJWkxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjevzC1OS9tE4v76l8Yy61pP4a2b26CWpcQa9JDVu7KBPcmKSzQOvR5O8dU6dM5I8MlDnXf2bLEnaF2OP0VfVd4FVAEkOA34A3DCk6peq6txxzyNJ6mexhm5eBnyvqr6/SMeTJC2Sxbrr5nzguhHbXpTkTmA78PaquntYpSTrgfUAK1asWKRmaal494h06Ojdo0/yZOCVwH8O2XwH8JyqOhn4IPDJUcepqg1VNV1V01NTU32bJUnqLMbQzdnAHVX1wNwNVfVoVf24W74JOCLJMYtwTknSAi1G0F/AiGGbJM9Kkm55dXe+Hy7COSVJC9RrjD7JbwBnAm8cKHsTQFVdAbwaeHOS3cBPgfOrqvqcU5K0b3oFfVX9BHjGnLIrBpYvBy7vcw5JUj8+GStJjTPoJalxBr0kNc6gl6TGGfSS1Dh/eETSRJnE6Tvs0UtS4wx6SWqcQS9JjXOMXhIwmWPXk8IevSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxvYM+ydYk30qyOcnMkO1J8i9J7k3yzSSn9D2nJGnhFuvJ2JdU1YMjtp0NnNC9TgU+3L1LkvaD/TF0cx7wkZr1VeDIJMv2w3klSSxOj76Azycp4F+rasOc7cuB+wfWt3VlOwYrJVkPrAdYsWLFIjRLh5Jx5lnZetk5S9CS9jmnzeRZjB796VV1CrNDNBcmefGc7RmyTz2hoGpDVU1X1fTU1NQiNEuSBIvQo6+q7d37ziQ3AKuBWweqbAOOH1g/Dtje97zSgba3nrH/t6GDSa8efZKnJnn6nmXgLOCuOdVuBF7f3X1zGvBIVe1AkrRf9O3RHwvckGTPsf6jqj6b5E0AVXUFcBOwFrgX+AnwFz3PKUnaB72CvqruA04eUn7FwHIBF/Y5jyRpfD4ZK0mNM+glqXEGvSQ1zqCXpMYZ9JLUuMWa1EyHOB+Ll9plj16SGmfQS1LjDHpJalxzY/ROdytJj2ePXpIaZ9BLUuMMeklqXHNj9NLBwOcSdDCxRy9JjbNHr0PWqF6zd1FJj2ePXpIaN3bQJzk+yS1JtiS5O8lFQ+qckeSRJJu717v6NVeStK/6DN3sBt5WVXd0PxB+e5JNVfXtOfW+VFXn9jiPJKmHsYO+qnYAO7rlx5JsAZYDc4P+oOfTtJJatihj9ElWAi8Ebhuy+UVJ7kzymSS/t5djrE8yk2Rm165di9EsSRKLEPRJngZ8HHhrVT06Z/MdwHOq6mTgg8AnRx2nqjZU1XRVTU9NTfVtliSp0yvokxzBbMhfW1WfmLu9qh6tqh93yzcBRyQ5ps85JUn7ps9dNwGuArZU1ftG1HlWV48kq7vz/XDcc0qS9l2fu25OB14HfCvJ5q7sncAKgKq6Ang18OYku4GfAudXVfU4pyRpH/W56+bLQOapczlw+bjnkCT15xQIhyhvCR2Pk41pEjkFgiQ1zqCXpMYZ9JLUOMfoJ4jj09JkskcvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapwPTKk5PhgmPZ49eklqnEEvSY0z6CWpcQa9JDWuV9AnWZPku0nuTXLxkO2/luT6bvttSVb2OZ8kad+NHfRJDgM+BJwNnARckOSkOdXeADxcVb8LvB/4p3HPJ0kaT5/bK1cD91bVfQBJPgqcB3x7oM55wLu75f8CLk+Sqqoe5z0oeAufpENFn6BfDtw/sL4NOHVUnaraneQR4BnAg3MPlmQ9sL5b/XGS747ZrmOGHX/CTPo1mPTPD14DOASvQfqNeTxn1IY+QZ8hZXN76gupM1tYtQHY0KM9sydMZqpquu9xDmWTfg0m/fOD1wC8BoP6fBm7DTh+YP04YPuoOkkOB34LeKjHOSVJ+6hP0H8dOCHJc5M8GTgfuHFOnRuBdd3yq4EvtDA+L0mHkrGHbrox97cAnwMOAzZW1d1JLgVmqupG4Crg35Pcy2xP/vzFaPQ8eg//NGDSr8Gkf37wGoDX4P/FDrYktc0nYyWpcQa9JDWumaCfbzqGFiXZmGRnkrsGyo5OsinJPd37UQeyjUstyfFJbkmyJcndSS7qyifmOiR5SpKvJbmzuwZ/35U/t5t65J5uKpInH+i2LqUkhyX5RpL/7tYn6vPvTRNBv8DpGFp0NbBmTtnFwM1VdQJwc7fest3A26rqecBpwIXdf/tJug4/A15aVScDq4A1SU5jdsqR93fX4GFmpyRp2UXAloH1Sfv8IzUR9AxMx1BVPwf2TMfQtKq6lSc+l3AecE23fA3wqv3aqP2sqnZU1R3d8mPM/kNfzgRdh5r14271iO5VwEuZnXoEGr8GSY4DzgGu7NbDBH3++bQS9MOmY1h+gNpyoB1bVTtgNgSBZx7g9uw33eyoLwRuY8KuQzdssRnYCWwCvgf8qKp2d1Va/zfxAeCvgV92689gsj7/XrUS9AueakFtSvI04OPAW6vq0QPdnv2tqn5RVauYfUJ9NfC8YdX2b6v2jyTnAjur6vbB4iFVm/z8C9HKj4MvZDqGSfFAkmVVtSPJMmZ7eE1LcgSzIX9tVX2iK5646wBQVT9K8kVmv684MsnhXa+25X8TpwOvTLIWeArwm8z28Cfl88+rlR79QqZjmBSD006sAz51ANuy5Lqx2KuALVX1voFNE3MdkkwlObJb/nXg5cx+V3ELs1OPQMPXoKreUVXHVdVKZv/tf6GqXsuEfP6FaObJ2O6v+Qf41XQM/3iAm7TkklwHnMHsdKwPAJcAnwQ+BqwA/hf4k6pqdiK5JL8PfAn4Fr8an30ns+P0E3EdkryA2S8bD2O28/axqro0yW8ze2PC0cA3gD+rqp8duJYuvSRnAG+vqnMn8fOP0kzQS5KGa2XoRpI0gkEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGvd/bWIVYdLENLwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.bar([i  for i in range(1, len(class_weights)+1)], class_weights, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VoQcmpa0UFCO"
   },
   "source": [
    "Clearly the data is **imbalanced**. We will have to mitigate this while training, one way of mitigating this is by using balanced class weights flag in Training algo.\n",
    "\n",
    "\n",
    "#### Feature Extraction\n",
    "We use couple of pre-processing technigues and tokenization to create a BOW model consisting of n-grams as features.\n",
    " \n",
    "1. Count Vectorization: This is used to count the frequency of words occuring per documents.\n",
    "2. Tf-Idf Vectorization : To mitigate effects of frequently occuring words/features we use Tf-Idf vectorization.\n",
    "3. Stop Words removal: Some common words such as 'a', 'the' etc may not be useful and can be removed from the text. \n",
    "4. Text cases: We try with lower casing of all words to prevent dupliacte words with different casing.\n",
    "5. N grams: We try using uni-gram, bi-gram and tri-grams.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_n2ycm6CPc3o"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def get_pipeline(clf=LogisticRegression()):\n",
    "  return Pipeline([\n",
    "          ('vect', CountVectorizer()),\n",
    "          ('tfidf', TfidfTransformer()),\n",
    "          ('clf', clf)])\n",
    "\n",
    "prep_processing_params={\n",
    "    'vect__max_features': (5000, 10000, 30000,),\n",
    "    'vect__ngram_range': ((1, 3),),\n",
    "    'vect__lowercase': (True, False),\n",
    "    'vect__stop_words': (None, 'english'),\n",
    "    #'vect__tokenizer': (StemTokenizer()),\n",
    "    ## 'vect__analyzer': ('word', 'char'),\n",
    "    'tfidf__norm': (['l2'])\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LGMYqwcY0pZG"
   },
   "source": [
    "## Algorithm: Logistic Regression\n",
    "We experiment with logistic regression. We will tune following parameters of Logistic Regression.\n",
    "\n",
    "__Logistic Regression Hyper-paramters__\n",
    "1. **Regularization**: This is the most important parameter that we use to control Over-Fitting. (Here, we have conducted some adhoc experimentation with C before finalising the given range.)\n",
    "2. **Class Weights**: This is used to mitigate the effect of **unbalanced classes**. We will try with both using balanced weights and non-balanced weights.\n",
    "3. We also experiment with max-iterations, multi_class and solver (multi_class: 'auto', 'ovr' Since, this is a multi-class prediction problem, we try with 'One-vs-Rest' strategy and 'Multinomial' loss.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ioDgyGlyDjWE"
   },
   "outputs": [],
   "source": [
    "lr_hyper_params={\n",
    "    'clf__C': ([  0.001, 0.1]),\n",
    "    'clf__class_weight': (['balanced', None]),  # This is to counteract unbalanced classes\n",
    "    'clf__max_iter': ([200, 400]),\n",
    "    'clf__multi_class': ([ 'auto']),\n",
    "    'clf__solver': ([ 'liblinear', 'newton-cg' ]), #''\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XUkufB3l3NWC"
   },
   "source": [
    "#### create pipeline with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lzLBWEvjDcb5"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters={}\n",
    "parameters.update(prep_processing_params)\n",
    "parameters.update(lr_hyper_params)\n",
    "\n",
    "grid_search = GridSearchCV(get_pipeline(),\n",
    "                           parameters,\n",
    "                           cv=5,                    #KFold KFoldStratified\n",
    "                           n_jobs=-1,\n",
    "                           refit=True,\n",
    "                           scoring='f1_weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AfiUV1LK3rD3"
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MQAIsAiW9o6E"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "colab_type": "code",
    "id": "NqUDF-FP3rMR",
    "outputId": "3e4b4e3e-85d2-4e05-8404-54b0368043d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sushil/opt/anaconda3/envs/deeplearning/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "path = '/content/gdrive/My Drive/models/'\n",
    "grid_search.fit(X_train_orig, train_labels)\n",
    "#joblib.dump(grid_search.best_estimator_, path + 'LGR_all.pkl', compress = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZFHg_TaMiz4w"
   },
   "source": [
    "#### Best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "4Rt5CKvYCNlr",
    "outputId": "aa8b81e6-4974-4e81-eb02-e6e6e1d39c57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "\tclf__C: '1e-02'\n",
      "\tclf__class_weight: ‘Balanced’\n",
      "\tclf__max_iter: 400\n",
      "\tclf__multi_class: 'auto'\n",
      "\tclf__solver: 'liblinear'\n",
      "\ttfidf__norm: 'l2'\n",
      "\tvect__lowercase: True\n",
      "\tvect__max_features: 5000\n",
      "\tvect__ngram_range: (1, 3)\n",
      "\tvect__stop_words: 'english'\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mwxmmb0Omt4p"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "2HnKxQ5PjzwK",
    "outputId": "e87d6ab8-e096-45f8-ddcf-1795b3c88234"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score 0.816015\n",
      "Confusion Matrix [[ 6  2  0 ...  0  0  0]\n",
      " [ 0 88  0 ...  0  0  0]\n",
      " [ 0  3 11 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  2  0  0]\n",
      " [ 0  1  0 ...  0  4  0]\n",
      " [ 0  0  0 ...  0  0  1]]\n",
      "[ 3 10  1  4 13  3  3  3  3  3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 3, 10,  1,  4,  4,  3,  3,  3,  3,  3])"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix\n",
    "\n",
    "test_result_proba = grid_search.predict_proba(X_test_orig)\n",
    "test_result = grid_search.predict(X_test_orig)\n",
    "\n",
    "#auc = roc_auc_score(test_labels, test_result_proba[:, 1])\n",
    "#print('Test ROC AUC: %.3f' % auc)\n",
    "\n",
    "fscore = f1_score(test_labels, test_result, average='weighted')\n",
    "print('F1 score %3f' % fscore)\n",
    "\n",
    "matrix = confusion_matrix(test_labels, test_result)\n",
    "print('Confusion Matrix', matrix)\n",
    "\n",
    "print(test_result[0:10])\n",
    "test_labels[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EAfT1yT8h9xy"
   },
   "source": [
    "### Conclusion \n",
    "Logistic Regression yields an F1-score of 0.81, which is better than the other MLP classifer.*italicized text* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZAZYn_ZWvNfv"
   },
   "source": [
    "## Algorithm: MLP Classifier\n",
    "We experiment with Multi-Layer Perceptron Classifier. We will tune following parameters of MLP.\n",
    "\n",
    "__MLP Hyper-paramters__\n",
    "1. **Alpha**:  Alpha in the range of (0.0000005, 0.00002, 0.001, 0.01). It is the learning rate.\n",
    "Among these 0.001 resulted in the best performance.\n",
    "2. **Activation  Functions**: Applied following activation functions ('logistic', 'tanh', 'relu'). It is found that logistic function gave the best F1 score (precision and recall). Tanh, Relu (which is the default) actually decreased the accuracy.\n",
    "3. **Layers**: Following hidden layer combinations are used ((50,), (50, 50), (100, ), (50, 50, 50))\n",
    "A network with (50,) hidden neruons was found to give best results in terms of F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5JbSMrzUvXBq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Best parameters set:\n",
       "\tclf__alpha: '1e-02'\n",
       "\tclf__hidden_layer_sizes: (50,)\n",
       "\tclf__max_iter: 200\n",
       "\tclf__batch_size: 200\n",
       "\tclf__activation: 'logistic'\n",
       "\ttfidf__norm: 'l2'\n",
       "\tvect__max_features: 10000\n",
       "\tvect__ngram_range: (1, 3)\n",
       "\tvect__lowercase': 'True'\n",
       "\tvect__tokenizer: <stemmer.StemTokenizer object at 0x126a2a898>\n",
       "\tvect__analyzer: 'char'\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MLPClassifier()),\n",
    "    ])\n",
    "\n",
    "hyper_params={\n",
    "    'clf__alpha': (0.0000005, 0.00002, 0.001, 0.01),\n",
    "    'clf__hidden_layer_sizes': ((50,), (50, 50), (100, ), (50, 50, 50)),\n",
    "    'clf__max_iter': (200, 400),\n",
    "    'clf__batch_size': (200,),\n",
    "    'clf__activation': (['logistic', 'tanh', 'relu'])\n",
    "}\n",
    "\n",
    "parameters={}\n",
    "parameters.update(hyper_params)\n",
    "parameters.update(prep_processing_params)\n",
    "\n",
    "grid_search = GridSearchCV(pipeline,\n",
    "                           parameters,\n",
    "                           cv=5,                    #KFold KFoldStratified\n",
    "                           n_jobs=-1,\n",
    "                           refit=True,\n",
    "                           scoring='f1_weighted')\n",
    "\n",
    "grid_search.fit(X_train_orig, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GjDmTKssxlie"
   },
   "source": [
    "### Testing models against test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sT9PdbzhxkGk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score 0.7240712\n",
      "Confusion Matrix [[ 9 0  0 ...  0  0  0]\n",
      " [ 0  19  0 ...  0  0  0]\n",
      " [ 0  23 4 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  5  0  0]\n",
      " [ 0  1  0 ...  0  7  0]\n",
      " [ 0  0  0 ...  0  0  8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix\n",
    "\n",
    "test_result_proba = grid_search.predict_proba(X_test_orig)\n",
    "test_result = grid_search.predict(X_test_orig)\n",
    "\n",
    "#auc = roc_auc_score(test_labels, test_result_proba[:, 1])\n",
    "#print('Test ROC AUC: %.3f' % auc)\n",
    "\n",
    "fscore = f1_score(test_labels, test_result, average='weighted')\n",
    "print('F1 score %3f' % fscore)\n",
    "\n",
    "matrix = confusion_matrix(test_labels, test_result)\n",
    "print('Confusion Matrix', matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YCzE26yOx_1G"
   },
   "source": [
    "### Conclusion \n",
    "MLP Classification yields an F1-score of 0.72, which is not as good as the Logistic Regression. Hence, Logistic Regression performs better in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Reuters",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
